{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 22:10:05.819889: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 22:10:11.717096: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('sentimental_distilbert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tokenizer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = tokenizer(text, \n",
    "                       max_length=512, \n",
    "                       truncation=True,\n",
    "                       padding='max_length',\n",
    "                       add_special_tokens=True,\n",
    "                       return_tensors='tf'\n",
    "                    )\n",
    "    \n",
    "    return {'input_ids': tokens['input_ids'], 'attention_mask': tokens['attention_mask']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['negative', 'somewhat negative', 'neutral', 'somewhat positive', 'positive']\n",
    "\n",
    "def make_prediction(text):\n",
    "    print(\"input: {}\".format(text))\n",
    "    probs = model.predict(tokenize(text))\n",
    "    print('prediction: {}\\n'.format(labels[np.argmax(probs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"No, this movie is amazing!\",\n",
    "    \"Yes, bro but this movie is horrible!\",\n",
    "    \"There is a book on the desk.\",\n",
    "    \"Not bad, not terrible, just ok!\",\n",
    "    \"I was skeptical at first but this show expectations by a mile!\",\n",
    "    \"I wanted to love..but there is no magic in this one\",\n",
    "    \"The core story is very interesting and after a dull start, the middle of the film really hits it's stride with Johnson moving his playing pieces about with ease and wonderment. That was when i most enjoyed the movie.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: No, this movie is amazing!\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "prediction: positive\n",
      "\n",
      "input: Yes, bro but this movie is horrible!\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "prediction: somewhat positive\n",
      "\n",
      "input: There is a book on the desk.\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "prediction: neutral\n",
      "\n",
      "input: Not bad, not terrible, just ok!\n",
      "1/1 [==============================] - 0s 309ms/step\n",
      "prediction: somewhat positive\n",
      "\n",
      "input: I was skeptical at first but this show expectations by a mile!\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "prediction: somewhat positive\n",
      "\n",
      "input: I wanted to love..but there is no magic in this one\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "prediction: somewhat positive\n",
      "\n",
      "input: The core story is very interesting and after a dull start, the middle of the film really hits it's stride with Johnson moving his playing pieces about with ease and wonderment. That was when i most enjoyed the movie.\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "prediction: somewhat positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    make_prediction(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Better pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b21fbb896e54eb2beccf164a39097e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/333 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a760ebfec6c941b09ce2fba7d89dc41d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7439558ae84433e9abe0adc7648389a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d20782312a8d47d9b66441bc85fc5ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c5b84c95074da8be828620dd7215eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/735 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ea70143b694fb5be2c91aeabdcadec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"lvwerra/distilbert-imdb\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"lvwerra/distilbert-imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, this movie is amazing!\n",
      "[{'label': 'POSITIVE', 'score': 0.9899942278862}]\n",
      "Yes, bro but this movie is horrible!\n",
      "[{'label': 'NEGATIVE', 'score': 0.9928169250488281}]\n",
      "There is a book on the desk.\n",
      "[{'label': 'POSITIVE', 'score': 0.5296631455421448}]\n",
      "Not bad, not terrible, just ok!\n",
      "[{'label': 'POSITIVE', 'score': 0.8404830098152161}]\n",
      "I was skeptical at first but this show expectations by a mile!\n",
      "[{'label': 'POSITIVE', 'score': 0.9020478129386902}]\n",
      "I wanted to love..but there is no magic in this one\n",
      "[{'label': 'NEGATIVE', 'score': 0.9615960121154785}]\n",
      "The core story is very interesting and after a dull start, the middle of the film really hits it's stride with Johnson moving his playing pieces about with ease and wonderment. That was when i most enjoyed the movie.\n",
      "[{'label': 'POSITIVE', 'score': 0.993565022945404}]\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    print(text)\n",
    "    print(pipe(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "465998d55d70973bbdaffa2598986d7a1a4bad5383a307a213b7a2e17d0ed72f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
