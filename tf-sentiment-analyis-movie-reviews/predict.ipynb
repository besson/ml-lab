{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 22:11:24.190889: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 22:12:39.260672: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('sentimental_distilbert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tokenizer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ccd4c29c21f4e66b7e1d18def8c74be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed63d9c30c9d41819d0e234bc027a595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = tokenizer(text, \n",
    "                       max_length=512, \n",
    "                       truncation=True,\n",
    "                       padding='max_length',\n",
    "                       add_special_tokens=True,\n",
    "                       return_tensors='tf'\n",
    "                    )\n",
    "    \n",
    "    return {'input_ids': tokens['input_ids'], 'attention_mask': tokens['attention_mask']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['negative', 'somewhat negative', 'neutral', 'somewhat positive', 'positive']\n",
    "\n",
    "def make_prediction(text):\n",
    "    print(\"input: {}\".format(text))\n",
    "    probs = model.predict(tokenize(text))\n",
    "    print('prediction: {}\\n'.format(labels[np.argmax(probs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"No, this movie is amazing!\",\n",
    "    \"Yes, bro but this movie is horrible!\",\n",
    "    \"There is a book on the desk.\",\n",
    "    \"Not bad, not terrible, just ok!\",\n",
    "    \"A very long long long text is the best way to confuse models like these one but if the model is very smart, it won't be confused with such simple tricks, don't you think that?\",\n",
    "    \"Canada is cold during the Winter\",\n",
    "    \"Brazil has grown to become one of the largest economies in the world. Still, Brazilian citizens rank quite low in income per capita.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: No, this movie is amazing!\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "prediction: positive\n",
      "\n",
      "input: Yes, bro but this movie is horrible!\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "prediction: somewhat positive\n",
      "\n",
      "input: There is a book on the desk.\n",
      "1/1 [==============================] - 0s 282ms/step\n",
      "prediction: neutral\n",
      "\n",
      "input: Not bad, not terrible, just ok!\n",
      "1/1 [==============================] - 0s 297ms/step\n",
      "prediction: somewhat positive\n",
      "\n",
      "input: A very long long long text is the best way to confuse models like these one but if the model is very smart, it won't be confused with such simples tricks, don't you think that?\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "prediction: somewhat negative\n",
      "\n",
      "input: Canada is cold during winter\n",
      "1/1 [==============================] - 0s 305ms/step\n",
      "prediction: neutral\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    make_prediction(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "465998d55d70973bbdaffa2598986d7a1a4bad5383a307a213b7a2e17d0ed72f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
